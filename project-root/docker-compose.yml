# VERSI FINAL DENGAN LAYANAN API
version: '3.8'

networks:
  app_network:
    driver: bridge

services:
  postgres-airflow:
    image: postgres:13
    container_name: dwh_postgres_airflow
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=airflow
    volumes:
      - postgres-airflow-data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U airflow"]
      interval: 5s
      timeout: 5s
      retries: 5
    networks:
      - app_network

  postgres-mlflow:
    image: postgres:13
    container_name: dwh_postgres_mlflow
    environment:
      - POSTGRES_USER=mlflow
      - POSTGRES_PASSWORD=mlflow
      - POSTGRES_DB=mlflow
    volumes:
      - mlflow_db_data_protected:/var/lib/postgresql/data
    ports:
      - "5433:5432"
    networks:
      - app_network

  airflow-init:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    container_name: project-root-airflow-init-1
    depends_on:
      postgres-airflow:
        condition: service_healthy
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres-airflow/airflow
    command: bash -c "airflow db reset -y && airflow db migrate && airflow users create --role Admin --username airflow --password airflow --firstname Anonymous --lastname User --email admin@example.com"
    networks:
      - app_network

  airflow-scheduler:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    container_name: project-root-airflow-scheduler-1
    depends_on:
      airflow-init:
        condition: service_completed_successfully
    volumes:
      - ./dags:/opt/airflow/dags
      - ./sql:/opt/airflow/sql
      - ./ml:/opt/airflow/ml
      - airflow-data:/opt/airflow/data
      - airflow-logs:/opt/airflow/logs
      - airflow-plugins:/opt/airflow/plugins
      - mlflow_artifacts_protected:/mlflow/artifacts
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres-airflow/airflow
      - AIRFLOW_CONN_POSTGRES_DEFAULT=postgresql://airflow:airflow@postgres-airflow:5432/airflow
    command: scheduler
    networks:
      - app_network

  airflow-webserver:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    container_name: project-root-airflow-webserver-1
    depends_on:
      airflow-init:
        condition: service_completed_successfully
      postgres-airflow:
        condition: service_healthy
    volumes:
      - ./dags:/opt/airflow/dags
      - ./sql:/opt/airflow/sql
      - ./ml:/opt/airflow/ml
      - airflow-data:/opt/airflow/data
      - airflow-logs:/opt/airflow/logs
      - airflow-plugins:/opt/airflow/plugins
    ports:
      - "8080:8080"
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres-airflow/airflow
      - AIRFLOW_CONN_POSTGRES_DEFAULT=postgresql://airflow:airflow@postgres-airflow:5432/airflow
    command: webserver
    healthcheck:
      test: ["CMD-SHELL", "curl --fail http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 5
    networks:
      - app_network

  mlflow:
    build:
      context: .
      dockerfile: Dockerfile.mlflow
    container_name: project_mlflow
    depends_on:
      postgres-mlflow:
        condition: service_started
    ports:
      - "5000:5000"
    command: >
      mlflow server
      --host 0.0.0.0
      --port 5000
      --backend-store-uri postgresql+psycopg2://mlflow:mlflow@postgres-mlflow/mlflow
      --default-artifact-root file:/mlflow/artifacts
    volumes:
      - mlflow_artifacts_protected:/mlflow/artifacts
    networks:
      - app_network

  metabase:
    image: metabase/metabase:v0.48.0
    container_name: project_metabase
    depends_on:
      - postgres-airflow
      - postgres-mlflow
    ports:
      - "3000:3000"
    volumes:
      - metabase_data_protected:/metabase.db
    networks:
      - app_network

  api:
    build:
      context: .
      dockerfile: Dockerfile.api
    container_name: project_api
    depends_on:
      - mlflow
    ports:
      - "8000:8000"
    volumes:
      - mlflow_artifacts_protected:/mlflow/artifacts
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow:5000
    networks:
      - app_network

volumes:
  postgres-airflow-data:
  airflow-data:
  airflow-logs:
  airflow-plugins:
  metabase_data_protected:
    external: true
  mlflow_db_data_protected:
    external: true
  mlflow_artifacts_protected:
    external: true
